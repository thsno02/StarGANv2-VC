{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue, os\n",
    "\n",
    "import datetime\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# enable to detect bluetooth devices, if and only if the devices are paired\n",
    "sd._terminate()\n",
    "sd._initialize()\n",
    "\n",
    "# show the available devices\n",
    "device_list = sd.query_devices()\n",
    "print(f'the device list is: \\n{device_list}.\\n')\n",
    "input_device = int(input('plz type the input device: '))\n",
    "output_device = int(input('plz type the output device: '))\n",
    "# set input and output devices\n",
    "sd.default.device = input_device, output_device\n",
    "\n",
    "fs = 24000\n",
    "sd.default.samplerate = fs  # set sample rate\n",
    "sd.default.channels = 1, 2  # one input channel, two output channel\n",
    "\n",
    "while True:\n",
    "        audio = np.zeros(\n",
    "            shape=(24000,\n",
    "                   1))  # add zero-filled buffer to promote the performance\n",
    "        q = queue.Queue()\n",
    "\n",
    "        def callback(in_data, frames, time, status):\n",
    "            q.put(in_data.copy())\n",
    "\n",
    "        try:\n",
    "            with sd.InputStream(samplerate=fs,\n",
    "                                device=input_device,\n",
    "                                dtype='float32',\n",
    "                                channels=1,\n",
    "                                callback=callback):\n",
    "\n",
    "                print('#' * 80)\n",
    "                print('press Ctrl+C to stop the recording')\n",
    "                print('#' * 80)\n",
    "                while True:\n",
    "                    audio = np.append(audio, q.get(), axis=0)\n",
    "        except KeyboardInterrupt:\n",
    "            print('end recording')\n",
    "        # pre-process audio\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "        audio = audio.flatten()  # flatten the 2D numpy array\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        content = input('plz type the content name: ')\n",
    "        file_name = '_'.join([content, timestamp, '.wav'])\n",
    "        path = os.path.join(os.getcwd, 'Test' + os.sep + 'Ref')\n",
    "        path = os.path.join(path, file_name)\n",
    "        t = librosa.output.write_wav(path, audio, fs, norm=False)\n",
    "        print(f'saved {file_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "A[load model] --> B[convert audio for each speaker] --> C[save the converted audio]\n",
    "C -- traverse all the speakers --> B\n",
    "C -- traverse all the models --> A\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from utils import load_starganv2\n",
    "\n",
    "model = Model()\n",
    "model_lists = [i for i in os.listdir('./Models/') if i.endswith('pth')]\n",
    "models_path = os.path.join(os.getcwd(), 'Models')\n",
    "\n",
    "test_path = os.path.join(os.getcwd(), 'Test')\n",
    "ref_path = os.path.join(test_path, 'Ref')\n",
    "conv_pth = os.path.join(test_path, 'Converted')\n",
    "\n",
    "for m in model_lists:\n",
    "    model_path = os.path.join(models_path, m)\n",
    "    model.starganv2 = load_starganv2(model_path)\n",
    "\n",
    "    for ref in os.listdir(ref_path):\n",
    "        if ref.endswith('wav'):\n",
    "            audio_path = os.path.join(ref_path, ref)\n",
    "            audio, sr = sf.read(audio_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for idx, sp in model.speakers.items():\n",
    "            converted_audio = model.infer(audio, idx)\n",
    "            # epoch-speaker-audio-timestamp.wav\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            file_name = '_'.join([m.split('.')[0], sp, ref.split('_')[0], timestamp, '.wav'])\n",
    "            conv_audio_path = os.path.join(conv_pth, file_name)\n",
    "            sf.write(conv_audio_path, converted_audio, fs, format='WAV')\n",
    "            print(f'saved {file_name}.')\n",
    "    \n",
    "    print(f'{m} has completed.\\n')"
   ]
<<<<<<< Updated upstream
=======
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a'.endswith('a')"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73b26bda67448e066e876fb3a5c3a56b69bad428bb00d7bd0b70474ad3f557e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
