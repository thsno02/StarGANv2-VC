{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check package available\n",
    "# REF: https://stackoverflow.com/questions/1051254/check-if-python-package-is-installed\n",
    "\n",
    "import importlib.util\n",
    "import sys, subprocess\n",
    "\n",
    "# For illustrative purposes.\n",
    "name = 'sounddevice'\n",
    "\n",
    "if name in sys.modules:\n",
    "    print(f\"{name!r} already in sys.modules\")\n",
    "elif (spec := importlib.util.find_spec(name)) is not None:\n",
    "    # If you choose to perform the actual import ...\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    print(f\"{name!r} has been imported\")\n",
    "else:\n",
    "    print(f\"can't find the {name!r} module\")\n",
    "    try:\n",
    "        cmd = f'pip install {name}'\n",
    "        t = subprocess.check_output(cmd, shell = True)\n",
    "        print(f'module {name} has been installed by pip.')\n",
    "    except:\n",
    "        print(f\"can't install {name} in pip, plz check the package name.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the input and output devices\n",
    "import sounddevice as sd\n",
    "\n",
    "# enable to detect bluetooth devices, if and only if the devices are paired\n",
    "sd._terminate()\n",
    "sd._initialize()\n",
    "\n",
    "# show the available devices\n",
    "device_list = sd.query_devices()\n",
    "print(f'the device list is: \\n{device_list}.\\n')\n",
    "for device in device_list:\n",
    "    if 'External Microphone' in device['name']:\n",
    "        input_device = device['name']\n",
    "        print(f\"Input device name is '{input_device}'.\")\n",
    "    elif 'External Headphones' in device['name']:\n",
    "        output_device = device['name']\n",
    "        print(f\"Output device name is '{output_device}'.\")\n",
    "\n",
    "sd.default.device = input_device, output_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the samplereate\n",
    "# REF: https://python-sounddevice.readthedocs.io/en/0.3.15/api/module-defaults.html\n",
    "fs = 24000\n",
    "sd.default.samplerate = fs\n",
    "sd.default.channels = 1, 2 # one input channel, two output channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice to Audio\n",
    "\n",
    "There are some issues:\n",
    "\n",
    "+ how to set the time interval?\n",
    "+ how to set the duration?\n",
    "  \n",
    "  I can set a long duration of this recording, and continue converting all the voice in this duration until terminate the VC program. This can be tricky, since this may require the system run two models at the same time, one is for KWS, another is for voice conversion. However, we don't wanna convert the keyword any more. Does this mean each voice segment should run KWS first, then VC? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the voice\n",
    "\n",
    "# TODO: how to set the duration?\n",
    "duration = 15 # seconds\n",
    "print('begin')\n",
    "audio = sd.rec(int(duration * fs), dtype = 'float32')\n",
    "# sd.playrec(myrecording, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Audio\n",
    "\n",
    "Two steps:\n",
    "\n",
    "- preprocess audio\n",
    "- infer the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "import os, random, time, librosa\n",
    "import torch\n",
    "\n",
    "from utils import compute_style, load_F0, load_starganv2, load_vocoder, preprocess, speakers\n",
    "\n",
    "global speakers\n",
    "F0_model = load_F0()\n",
    "vocoder = load_vocoder()\n",
    "starganv2 = load_starganv2()\n",
    "\n",
    "def convert(audio, speaker, F0_model, vocoder, starganv2):\n",
    "    '''@lw\n",
    "    :speaker: the speaker name\n",
    "    '''\n",
    "\n",
    "    # # @lw: unify the speaker to the speaker name\n",
    "    # if isinstance(speaker, int):\n",
    "    #     speaker = speakers[speaker]\n",
    "    # else:\n",
    "    #     # @lw: check whether the speaker in the list\n",
    "    #     assert speaker in speakers.values(\n",
    "    #     ), 'we only support the following speakers: {}.'.format('; '.join(\n",
    "    #         speakers.values()))\n",
    "\n",
    "    # @lw: set reference, get the speaker index\n",
    "    speaker_dicts = {speaker: ('', speakers[speaker])}\n",
    "\n",
    "    # @lw: compute reference embeddings\n",
    "    reference_embeddings = compute_style(speaker_dicts)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # conversion\n",
    "    source = preprocess(audio).to('cuda:0')\n",
    "    converted_audio = None\n",
    "\n",
    "    for key, (ref, _) in reference_embeddings.items():\n",
    "        with torch.no_grad():\n",
    "            f0_feat = F0_model.get_feature_GAN(source.unsqueeze(1))\n",
    "            out = starganv2.generator(source.unsqueeze(1), ref, F0=f0_feat)\n",
    "\n",
    "            c = out.transpose(-1, -2).squeeze().to('cuda')\n",
    "            y_out = vocoder.inference(c)\n",
    "            y_out = y_out.view(-1).cpu()\n",
    "\n",
    "        converted_audio = y_out.numpy()\n",
    "\n",
    "    end = time.time()\n",
    "    print('{} total processing time: {:.3f} sec'.format(type, end - start))\n",
    "\n",
    "    return converted_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess audio\n",
    "import numpy as np\n",
    "\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "converted_audio = convert(audio, speaker, F0_model, vocoder, starganv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Processed Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(converted_audio, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "t = np.array([[1,2,3]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "fs = 24000\n",
    "sd.default.samplerate = fs\n",
    "sd.default.channels = 1, 2 # one input channel, two output channel\n",
    "duration = 5 # seconds\n",
    "print('begin')\n",
    "audio = sd.rec(int(duration * fs), dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio / np.max(np.abs(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio.flatten()) == len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timedate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "def get_time_dif(start_time):\n",
    "    end_time = time.time()\n",
    "    return round(end_time - start_time, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_time_dif(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='inference.log',\n",
    "                    encoding='utf-8',\n",
    "                    level=logging.DEBUG)\n",
    "logging.debug('This message should go to the log file')\n",
    "logging.info('So should this')\n",
    "logging.warning('And this, too')\n",
    "logging.error('And non-ASCII stuff, too, like Øresund and Malmö')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "FORMAT = '%(asctime)s %(clientip)-15s %(user)-8s %(message)s'\n",
    "logging.basicConfig(filename='inference.log',format=FORMAT,\n",
    "                    encoding='utf-8',\n",
    "                    level=logging.DEBUG)\n",
    "d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}\n",
    "logger = logging.getLogger('tcpserver')\n",
    "logger.warning('Protocol problem: %s', 'connection reset', extra=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Nump Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.array([1,2,3,4,5,6])\n",
    "l = len(t)\n",
    "d = [i for i in range(l) if i % 2 == 1]\n",
    "t = np.delete(t, d, None)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "q = queue.Queue()\n",
    "q.put([1])\n",
    "q.put([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.deque()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b26bda67448e066e876fb3a5c3a56b69bad428bb00d7bd0b70474ad3f557e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
