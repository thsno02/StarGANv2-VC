{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sounddevice' already in sys.modules\n"
     ]
    }
   ],
   "source": [
    "# check package available\n",
    "# REF: https://stackoverflow.com/questions/1051254/check-if-python-package-is-installed\n",
    "\n",
    "import importlib.util\n",
    "import sys, subprocess\n",
    "\n",
    "# For illustrative purposes.\n",
    "name = 'sounddevice'\n",
    "\n",
    "if name in sys.modules:\n",
    "    print(f\"{name!r} already in sys.modules\")\n",
    "elif (spec := importlib.util.find_spec(name)) is not None:\n",
    "    # If you choose to perform the actual import ...\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    print(f\"{name!r} has been imported\")\n",
    "else:\n",
    "    print(f\"can't find the {name!r} module\")\n",
    "    try:\n",
    "        cmd = f'pip install {name}'\n",
    "        t = subprocess.check_output(cmd, shell = True)\n",
    "        print(f'module {name} has been installed by pip.')\n",
    "    except:\n",
    "        print(f\"can't install {name} in pip, plz check the package name.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the device list is: \n",
      "  0 dnhb's AirPods, Core Audio (1 in, 0 out)\n",
      "  1 dnhb's AirPods, Core Audio (0 in, 2 out)\n",
      "> 2 External Microphone, Core Audio (1 in, 0 out)\n",
      "< 3 External Headphones, Core Audio (0 in, 2 out)\n",
      "  4 MacBook Pro Microphone, Core Audio (1 in, 0 out)\n",
      "  5 MacBook Pro Speakers, Core Audio (0 in, 2 out)\n",
      "  6 ZoomAudioDevice, Core Audio (2 in, 2 out).\n",
      "\n",
      "Input device name is 'External Microphone'.\n",
      "Output device name is 'External Headphones'.\n"
     ]
    }
   ],
   "source": [
    "# set the input and output devices\n",
    "import sounddevice as sd\n",
    "\n",
    "# enable to detect bluetooth devices, if and only if the devices are paired\n",
    "sd._terminate()\n",
    "sd._initialize()\n",
    "\n",
    "# show the available devices\n",
    "device_list = sd.query_devices()\n",
    "print(f'the device list is: \\n{device_list}.\\n')\n",
    "for device in device_list:\n",
    "    if 'External Microphone' in device['name']:\n",
    "        input_device = device['name']\n",
    "        print(f\"Input device name is '{input_device}'.\")\n",
    "    elif 'External Headphones' in device['name']:\n",
    "        output_device = device['name']\n",
    "        print(f\"Output device name is '{output_device}'.\")\n",
    "\n",
    "sd.default.device = input_device, output_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the samplereate\n",
    "# REF: https://python-sounddevice.readthedocs.io/en/0.3.15/api/module-defaults.html\n",
    "fs = 24000\n",
    "sd.default.samplerate = fs\n",
    "sd.default.channels = 1, 2 # one input channel, two output channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice to Audio\n",
    "\n",
    "There are some issues:\n",
    "\n",
    "+ how to set the time interval?\n",
    "+ how to set the duration?\n",
    "  \n",
    "  I can set a long duration of this recording, and continue converting all the voice in this duration until terminate the VC program. This can be tricky, since this may require the system run two models at the same time, one is for KWS, another is for voice conversion. However, we don't wanna convert the keyword any more. Does this mean each voice segment should run KWS first, then VC? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n"
     ]
    }
   ],
   "source": [
    "# Record the voice\n",
    "\n",
    "# TODO: how to set the duration?\n",
    "duration = 15 # seconds\n",
    "print('begin')\n",
    "audio = sd.rec(int(duration * fs), dtype = 'float32')\n",
    "# sd.playrec(myrecording, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Audio\n",
    "\n",
    "Two steps:\n",
    "\n",
    "- preprocess audio\n",
    "- infer the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOLS\n",
    "import os, random, time, librosa\n",
    "import torch\n",
    "\n",
    "from utils import compute_style, load_F0, load_starganv2, load_vocoder, preprocess, speakers\n",
    "\n",
    "global speakers\n",
    "F0_model = load_F0()\n",
    "vocoder = load_vocoder()\n",
    "starganv2 = load_starganv2()\n",
    "\n",
    "def convert(audio, speaker, F0_model, vocoder, starganv2):\n",
    "    '''@lw\n",
    "    :speaker: the speaker name\n",
    "    '''\n",
    "\n",
    "    # # @lw: unify the speaker to the speaker name\n",
    "    # if isinstance(speaker, int):\n",
    "    #     speaker = speakers[speaker]\n",
    "    # else:\n",
    "    #     # @lw: check whether the speaker in the list\n",
    "    #     assert speaker in speakers.values(\n",
    "    #     ), 'we only support the following speakers: {}.'.format('; '.join(\n",
    "    #         speakers.values()))\n",
    "\n",
    "    # @lw: set reference, get the speaker index\n",
    "    speaker_dicts = {speaker: ('', speakers[speaker])}\n",
    "\n",
    "    # @lw: compute reference embeddings\n",
    "    reference_embeddings = compute_style(speaker_dicts)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # conversion\n",
    "    source = preprocess(audio).to('cuda:0')\n",
    "    converted_audio = None\n",
    "\n",
    "    for key, (ref, _) in reference_embeddings.items():\n",
    "        with torch.no_grad():\n",
    "            f0_feat = F0_model.get_feature_GAN(source.unsqueeze(1))\n",
    "            out = starganv2.generator(source.unsqueeze(1), ref, F0=f0_feat)\n",
    "\n",
    "            c = out.transpose(-1, -2).squeeze().to('cuda')\n",
    "            y_out = vocoder.inference(c)\n",
    "            y_out = y_out.view(-1).cpu()\n",
    "\n",
    "        converted_audio = y_out.numpy()\n",
    "\n",
    "    end = time.time()\n",
    "    print('{} total processing time: {:.3f} sec'.format(type, end - start))\n",
    "\n",
    "    return converted_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess audio\n",
    "import numpy as np\n",
    "\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "converted_audio = convert(audio, speaker, F0_model, vocoder, starganv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Processed Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.playrec(converted_audio, fs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b26bda67448e066e876fb3a5c3a56b69bad428bb00d7bd0b70474ad3f557e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
