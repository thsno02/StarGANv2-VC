{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml \n",
    "import yaml\n",
    "\n",
    "config_path = 'Configs/config.yml'\n",
    "config = yaml.safe_load(open(config_path))\n",
    "print(\"batch size in config is {}; config.get('batch_size', 10) returns a batch size with {}.\".format(\n",
    "    config['batch_size'], config.get('batch_size', 10)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess\n",
    "\n",
    "1. convert video to audio\n",
    "2. cut the audio into 2-second segments, and check its attributions\n",
    "3. check the availability\n",
    "   1. Python Script\n",
    "   2. human filter\n",
    "4. select 20mins audio for each speaker\n",
    "5. add these audio files into the train_list.txt and val_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the demo audio format\n",
    "\n",
    "import sndhdr, os\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), 'Demo' + os.sep + 'VCTK-corpus')\n",
    "for i in os.listdir(audio_path):\n",
    "    speaker_path = os.path.join(audio_path, i)\n",
    "    # check whether a dir\n",
    "    if os.path.isdir(speaker_path):\n",
    "        for a in os.listdir(speaker_path):\n",
    "            file_path = os.path.join(speaker_path, a)\n",
    "            print('{} {}'.format(a, sndhdr.what(file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the videos\n",
    "\n",
    "import os \n",
    "\n",
    "video_path = os.path.join(os.getcwd(), 'Video')\n",
    "for speaker in os.listdir(video_path):\n",
    "    speaker_path = os.path.join(video_path, speaker)\n",
    "    cnt = 0\n",
    "    if os.path.isdir(speaker_path):\n",
    "        for file in os.listdir(speaker_path):\n",
    "            if '_' not in file:\n",
    "                cnt += 1\n",
    "                input_file = os.path.join(speaker_path, file)\n",
    "                output_name = '{}_{}.mp4'.format(speaker, cnt)\n",
    "                output_file = os.path.join(speaker_path, output_name)\n",
    "                os.rename(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert video to audio\n",
    "\n",
    "# install dependency\n",
    "# REF: https://blog.fat-nerds.com/dot-nerd/install-ffmpeg-mac-os-in-chinese/\n",
    "# %brew install ffmpeg\n",
    "\n",
    "import os, subprocess, sndhdr\n",
    "\n",
    "# REF: https://ffmpeg.org/ffmpeg.html#Audio-Options\n",
    "###\n",
    "# :i: input\n",
    "# :-ac: Set the number of audio channels.\n",
    "# :-ar: Set the audio sampling frequency.\n",
    "# :-sample_fmt: Set the audio sample format.\n",
    "# :-c:a: select ann encoder\n",
    "# :-y: Overwrite output files without asking\n",
    "###\n",
    "\n",
    "video_path = os.path.join(os.getcwd(), 'Video')\n",
    "for speaker in os.listdir(video_path):\n",
    "    speaker_path = os.path.join(video_path, speaker)\n",
    "    if os.path.isdir(speaker_path):\n",
    "        for file in os.listdir(speaker_path):\n",
    "            if file.endswith('.DS_Store'):\n",
    "                continue\n",
    "            input_file = os.path.join(speaker_path, file)\n",
    "            # output file name\n",
    "            output_name = file.split('.')[0] + '.wav'\n",
    "            # output file path\n",
    "            output_file = os.path.join(os.getcwd() + os.sep + 'Data' + os.sep + 'raw', output_name)\n",
    "            # print(input_file, output_file)\n",
    "            convert_cmd = 'ffmpeg -i {} -y -ac 1 -ar 24000 -c:a pcm_s16le {}'.format(input_file, output_file)\n",
    "            # print(convert_cmd)\n",
    "            s = subprocess.run(convert_cmd, shell = True, check = True)\n",
    "            # s = os.system(convert_cmd)\n",
    "            # print('done')\n",
    "            assert sndhdr.what(output_file)[0] == 'wav', '{audio} {output_name} filetype'\n",
    "            assert sndhdr.what(output_file)[1] == 24000, '{audio} {output_name} framerate'\n",
    "            assert sndhdr.what(output_file)[2] == 1, '{audio} {output_name} nchannels'\n",
    "            assert sndhdr.what(output_file)[4] == 16, '{audio} {output_name} sampwidth'\n",
    "            # print('{} {}'.format(output_name, sndhdr.what(output_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the whole audio into 2-second segments\n",
    "\n",
    "import os, subprocess, sndhdr\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'Data')\n",
    "raw_path = os.path.join(data_path, 'raw')\n",
    "\n",
    "def get_duration(file):\n",
    "    \"\"\"\n",
    "    Get the duration of the file, returns the seconds\n",
    "    \"\"\"\n",
    "    cmd_get_audio_message = \"ffmpeg -i \" + file + \" 2>&1| grep 'Duration' | cut -d ' ' -f 4 | sed s/,//\"\n",
    "    time_str = os.popen(cmd_get_audio_message).readlines()[0].strip('\\n').strip('\\r')\n",
    "    time_hour = int(time_str.split(':')[0])\n",
    "    time_minute = int(time_str.split(':')[1])\n",
    "    time_second = int(time_str.split(':')[2].split('.')[0])\n",
    "    return time_hour * 3600 + time_minute * 60 + time_second\n",
    "\n",
    "def cut_segments(audio: str, raw_path, data_path, duration = 2):\n",
    "    \"\"\"\n",
    "    Cut the audio into 2-second segments, and put it into speaker data path\n",
    "    :duration: n seconds\n",
    "    \"\"\"\n",
    "    cut_duration = duration  # second\n",
    "    audio_path = os.path.join(raw_path, audio)\n",
    "    speaker_name = '_'.join(audio.split('_')[:2])\n",
    "    speaker_data_path = os.path.join(data_path, speaker_name)\n",
    "    audio_duration = get_duration(audio_path)\n",
    "    # get the data length\n",
    "    cnt = 0 # continue with the existing cnt\n",
    "    for f in os.listdir(speaker_data_path):\n",
    "        if f.endswith('.wav'):\n",
    "            cnt += 1 \n",
    "    for i in range(audio_duration//cut_duration): \n",
    "        cnt += 1\n",
    "        output_name = '{}_{:05}.wav'.format(speaker_name, cnt)\n",
    "        output_file = os.path.join(speaker_data_path, output_name)\n",
    "        cut_cmd = 'ffmpeg -y -ss {start_point} -i {input_file} -t {end_point} -c copy {output_file}'.format(\n",
    "            start_point = i * cut_duration, end_point = cut_duration, input_file = audio_path, output_file = output_file\n",
    "        )\n",
    "        # print(cut_cmd)\n",
    "        # subprocess occurs 'FFmpeg returned non-zero exit status 1' error\n",
    "        s = subprocess.check_output(cut_cmd, shell = True)\n",
    "        # s = os.system(cut_cmd)\n",
    "        assert sndhdr.what(output_file)[0] == 'wav', '{audio} {output_name} filetype'\n",
    "        assert sndhdr.what(output_file)[1] == 24000, '{audio} {output_name} framerate'\n",
    "        assert sndhdr.what(output_file)[2] == 1, '{audio} {output_name} nchannels'\n",
    "        assert sndhdr.what(output_file)[4] == 16, '{audio} {output_name} sampwidth'\n",
    "    # print('{} is complete.'.format(audio))\n",
    "\n",
    "for audio in sorted(os.listdir(raw_path)):\n",
    "    if not audio.endswith('.wav'):\n",
    "        continue\n",
    "    if audio.startswith('Luo_Xiang'):\n",
    "        cut_segments(audio, raw_path, data_path, duration = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct train_list and val_list\n",
    "\n",
    "import random, os\n",
    "\n",
    "speakers = []\n",
    "video_path = os.path.join(os.getcwd(), 'Video')\n",
    "data_path = os.path.join('.', 'Data') # get the relative dir\n",
    "train_list_path = os.path.join(data_path, 'train_list.txt')\n",
    "if os.path.exists(train_list_path):\n",
    "    os.remove(train_list_path) # remove if exists\n",
    "val_list_path = os.path.join(data_path, 'val_list.txt')\n",
    "if os.path.exists(val_list_path):\n",
    "    os.remove(val_list_path)\n",
    "\n",
    "# get the speakers\n",
    "for speaker in os.listdir(video_path):\n",
    "    if speaker == '.DS_Store':\n",
    "        continue\n",
    "    speakers.append(speaker)\n",
    "speakers.sort() # get fixed order\n",
    "for i in enumerate(speakers):\n",
    "    print(i)\n",
    "\n",
    "# get the training data\n",
    "for speaker in os.listdir(data_path):\n",
    "    if speaker not in speakers:\n",
    "        continue\n",
    "    speaker_path = os.path.join(data_path, speaker)\n",
    "    files = os.listdir(speaker_path)\n",
    "    random.seed(2022)\n",
    "    random.shuffle(files)\n",
    "    train_data = files[:100]\n",
    "    # train_data = files[:600]\n",
    "    val_data = files[600:675]\n",
    "    for f in train_data:\n",
    "        f_path = os.path.join(speaker_path, f)\n",
    "        f_name = f'{f_path}|{speakers.index(speaker)}'\n",
    "        with open(train_list_path, 'a') as f:\n",
    "            _ = f.write(f_name + '\\n') # use _ to avoid the output character\n",
    "    for f in val_data:\n",
    "        f_path = os.path.join(speaker_path, f)\n",
    "        f_name = f'{f_path}|{speakers.index(speaker)}'\n",
    "        with open(val_list_path, 'a') as f:\n",
    "            _ = f.write(f_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pred segments\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'Data')\n",
    "raw_path = os.path.join(data_path, 'raw')\n",
    "data_path = os.path.join(os.getcwd(), 'Pred' + os.sep + 'yisa')\n",
    "\n",
    "for audio in sorted(os.listdir(raw_path)):\n",
    "    if not audio.endswith('.wav'):\n",
    "        continue\n",
    "    cut_segments(audio, raw_path, data_path, duration = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Domain Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "m = torch.load('./Models/yisa/epoch_v2_00248.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Dong_Mingzhu',\n",
       " 1: 'Hua_Chunying',\n",
       " 2: 'Li_Fanping',\n",
       " 3: 'Li_Gan',\n",
       " 4: 'Luo_Xiang',\n",
       " 5: 'Ma_Yun',\n",
       " 6: 'Shi_Zhuguo',\n",
       " 7: 'Wang_Cheng',\n",
       " 8: 'Wang_Kun',\n",
       " 9: 'Zhao_Lijian'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = {\n",
    "    0: 'Li_Fanping',\n",
    "    1: 'Shi_Zhuguo',\n",
    "    2: 'Wang_Cheng',\n",
    "    3: 'Wang_Kun',\n",
    "    4: 'Zhao_Lijian',\n",
    "    5: 'Hua_Chunying',\n",
    "    6: 'Luo_Xiang',\n",
    "    7: 'Li_Gan',\n",
    "    8: 'Dong_Mingzhu',\n",
    "    9: 'Ma_Yun'\n",
    "}\n",
    "\n",
    "k = sorted(speakers.values())\n",
    "s = {}\n",
    "for d in enumerate(k):\n",
    "    s[d[0]] = d[1]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b26bda67448e066e876fb3a5c3a56b69bad428bb00d7bd0b70474ad3f557e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
